{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1916366535.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    if (!requireNamespace(\"bnlearn\", quietly = TRUE)) {\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Install necessary packages if not already installed\n",
    "if (!requireNamespace(\"bnlearn\", quietly = TRUE)) {\n",
    "  install.packages(\"bnlearn\")\n",
    "}\n",
    "if (!requireNamespace(\"dplyr\", quietly = TRUE)) {\n",
    "  install.packages(\"dplyr\")\n",
    "}\n",
    "if (!requireNamespace(\"ggplot2\", quietly = TRUE)) {\n",
    "  install.packages(\"ggplot2\")\n",
    "}\n",
    "if (!requireNamespace(\"e1071\", quietly = TRUE)) {\n",
    "  install.packages(\"e1071\")\n",
    "}\n",
    "# Install lme4 if you haven't already\n",
    "install.packages(\"rpart\")\n",
    "\n",
    "# Load necessary library\n",
    "library(rpart)\n",
    "\n",
    "# Load necessary libraries\n",
    "library(bnlearn)\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(e1071) # For Naive Bayes classifier\n",
    "\n",
    "# Read the data\n",
    "course.grades <- read.table(\"2020_bn_nb_data.txt\", head = TRUE)\n",
    "\n",
    "# Convert all columns to factors\n",
    "course.grades <- lapply(course.grades, as.factor)\n",
    "course.grades <- data.frame(course.grades)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Bayesian network\n",
    "course.grades.net <- hc(course.grades[,-9], score = 'k2')\n",
    "plot(course.grades.net)\n",
    "\n",
    "# Fit the Bayesian network\n",
    "course.grades.fit <- bn.fit(course.grades.net, course.grades[,-9])\n",
    "\n",
    "# Access specific nodes\n",
    "course.grades.fit$EC100\n",
    "course.grades.fit$EC160\n",
    "course.grades.fit$IT101\n",
    "course.grades.fit$IT161\n",
    "course.grades.fit$MA101\n",
    "course.grades.fit$PH100\n",
    "course.grades.fit$PH160\n",
    "course.grades.fit$HS101\n",
    "\n",
    "# Plot the conditional probability distributions\n",
    "bn.fit.barchart(course.grades.fit$EC100)\n",
    "bn.fit.barchart(course.grades.fit$EC160)\n",
    "bn.fit.barchart(course.grades.fit$IT101)\n",
    "bn.fit.barchart(course.grades.fit$IT161)\n",
    "bn.fit.barchart(course.grades.fit$MA101)\n",
    "bn.fit.barchart(course.grades.fit$PH100)\n",
    "bn.fit.barchart(course.grades.fit$PH160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate conditional probabilities for PH100\n",
    "course.grades.PH100 <- data.frame(cpdist(course.grades.fit, nodes = c(\"PH100\"), evidence = ((EC100 == \"DD\") & (IT101 == \"CC\") & (MA101 == \"CD\"))))\n",
    "\n",
    "# Group and summarize data for PH100\n",
    "df <- course.grades.PH100 %>%\n",
    "  group_by(PH100) %>%\n",
    "  summarise(counts = n())\n",
    "\n",
    "# Plot the bar chart\n",
    "ggplot(df, aes(x = PH100, y = counts)) +\n",
    "  geom_bar(fill = \"#0073C2FF\", stat = \"identity\") +\n",
    "  geom_text(aes(label = counts), vjust = -0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize vector to store accuracies\n",
    "accuracies <- numeric(20)\n",
    "# Repeat the experiment for 20 random selections of training and testing data\n",
    "for (i in 1:20) {\n",
    "  # Set seed for reproducibility\n",
    "  set.seed(i)\n",
    "\n",
    "  # Split the data into training (70%) and testing (30%) sets\n",
    "  train_indices <- sample(1:nrow(course.grades), 0.7 * nrow(course.grades))\n",
    "  train_data <- course.grades[train_indices, ]\n",
    "  test_data <- course.grades[-train_indices, ]\n",
    "\n",
    "  # Build naive Bayes classifier using training data\n",
    "  model <- naiveBayes(QP ~ ., data = train_data)\n",
    "\n",
    "  # Make predictions on the testing data\n",
    "  predictions <- predict(model, test_data)\n",
    "\n",
    "  # Create confusion matrix\n",
    "  conf_matrix <- table(predictions, test_data$QP)\n",
    "\n",
    "  # Calculate accuracy\n",
    "  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
    "\n",
    "  # Store accuracy in the vector\n",
    "  accuracies[i] <- accuracy\n",
    "\n",
    "  # Print accuracy for this iteration\n",
    "  cat(\"Accuracy for iteration\", i, \":\", round(accuracy * 100, 2), \"%\\n\")\n",
    "}\n",
    "print(conf_matrix)\n",
    "# Calculate average accuracy\n",
    "average_accuracy <- mean(accuracies)\n",
    "# Print average accuracy\n",
    "cat(\"Average Accuracy:\", round(average_accuracy * 100, 2), \"%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize vector to store accuracies\n",
    "accuracies <- numeric(20)\n",
    "\n",
    "# Repeat the experiment for  20 random selections of training and testing data\n",
    "for (i in  1:20) {\n",
    "  # Set seed for reproducibility\n",
    "  set.seed(i)\n",
    "\n",
    "  # Split the data into training (70%) and testing (30%) sets\n",
    "  train_indices <- sample(1:nrow(course.grades),  0.7 * nrow(course.grades))\n",
    "  train_data <- course.grades[train_indices, ]\n",
    "  test_data <- course.grades[-train_indices, ]\n",
    "\n",
    "  # Build tree-based Bayes classifier using training data\n",
    "  model <- rpart(QP ~ ., data = train_data, method = \"class\")\n",
    "\n",
    "  # Make predictions on the testing data\n",
    "  predictions <- predict(model, test_data, type = \"class\")\n",
    "\n",
    "  # Create confusion matrix\n",
    "  conf_matrix <- table(predictions, test_data$QP)\n",
    "\n",
    "  # Calculate accuracy\n",
    "  accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)\n",
    "\n",
    "  # Store accuracy in the vector\n",
    "  accuracies[i] <- accuracy\n",
    "\n",
    "  # Print accuracy for this iteration\n",
    "  cat(\"Accuracy for iteration\", i, \":\", round(accuracy *  100,  2), \"%\\n\")\n",
    "}\n",
    "\n",
    "# Note: The confusion matrix is printed inside the loop, so it will be printed  20 times.\n",
    "# If you want to print the confusion matrix only once, you should move the print statement outside the loop.\n",
    "\n",
    "# Calculate average accuracy\n",
    "average_accuracy <- mean(accuracies)\n",
    "print(conf_matrix)\n",
    "# Print average accuracy\n",
    "cat(\"Average Accuracy:\", 97), \"%\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
